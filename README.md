# AI Edge Accelerator - CNN Inference Engine

## ZUBoard 1CG FPGA Project for Real-Time Object Detection and Classification

[![Target Device](https://img.shields.io/badge/Device-xczu1cg--sbva484--1--e-blue)](https://www.xilinx.com/products/silicon-devices/soc/zynq-ultrascale-mpsoc.html)
[![Board](https://img.shields.io/badge/Board-ZUBoard%201CG-green)](https://www.avnet.com/wps/portal/us/products/avnet-boards/avnet-board-families/zuboard-1cg/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## ğŸ“‹ Overview

This project implements a **custom CNN (Convolutional Neural Network) inference engine** on the Zynq UltraScale+ ZU1CG FPGA. It is designed for **real-time object detection and image classification** at the edge, with camera input via DMA and optimized processing pipelines.

### Key Features

- ğŸ§  **Custom CNN Hardware Accelerator** - Conv2D, Pooling, Activation in RTL
- ğŸ“· **Camera Input via DMA** - AXI-Stream interface for video frames
- âš¡ **Real-time Processing** - Designed for >30 FPS on 128x128 images
- ğŸ”§ **Configurable Architecture** - Adjustable layers, filters, and parameters
- ğŸ“Š **Performance Counters** - Built-in cycle and operation counting
- ğŸ”Œ **AXI-Lite Control** - Easy software integration and configuration

---

## ğŸ—ï¸ Architecture

### CNN Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AI Edge Accelerator System                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Camera  â”‚â”€â”€â”€â–¶â”‚ AXI DMA      â”‚â”€â”€â”€â–¶â”‚ Video Input  â”‚â”€â”€â”€â–¶â”‚ Conv2D #0    â”‚   â”‚
â”‚  â”‚ (MIPI)  â”‚    â”‚ Video        â”‚    â”‚ Preprocessor â”‚    â”‚ 3x3, 16 filt â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ PS      â”‚â”€â”€â”€â–¶â”‚ AXI-Lite     â”‚â”€â”€â”€â–¶â”‚ CNN Control  â”‚    â”‚ MaxPool #0   â”‚   â”‚
â”‚  â”‚ CPU     â”‚    â”‚ Interface    â”‚    â”‚ Registers    â”‚    â”‚ 2x2          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ DDR4    â”‚â—€â”€â”€â–¶â”‚ AXI DMA      â”‚â—€â”€â”€â”€â”‚ Result       â”‚â—€â”€â”€â”€â”‚ Conv2D #1    â”‚   â”‚
â”‚  â”‚ Memory  â”‚    â”‚ Weights      â”‚    â”‚ Output       â”‚    â”‚ 3x3, 32 filt â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚          â”‚
â”‚                                                          â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                                                          â”‚ MaxPool #1   â”‚   â”‚
â”‚                                                          â”‚ 2x2          â”‚   â”‚
â”‚                                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

1. **Video Input**: RGB frames from camera via AXI-Stream DMA
2. **Preprocessing**: RGB to fixed-point Q8.8 normalization
3. **Conv2D Layers**: 3x3 convolution with configurable filters
4. **Activation**: ReLU, Leaky ReLU, Sigmoid (LUT-based)
5. **Pooling**: 2x2 Max or Average pooling
6. **Output**: Classification probabilities

---

## ğŸ“ Project Structure

```
zuboard_ai-edge-accelerator/
â”œâ”€â”€ rtl/
â”‚   â”œâ”€â”€ cnn/
â”‚   â”‚   â”œâ”€â”€ cnn_pkg.vhd              # CNN types and functions package
â”‚   â”‚   â”œâ”€â”€ cnn_accelerator_top.vhd  # Top-level accelerator module
â”‚   â”‚   â”œâ”€â”€ conv2d_engine.vhd        # 2D convolution with MAC array
â”‚   â”‚   â”œâ”€â”€ pooling_engine.vhd       # Max/Average pooling
â”‚   â”‚   â”œâ”€â”€ activation_unit.vhd      # Activation functions (LUT-based)
â”‚   â”‚   â””â”€â”€ batchnorm_unit.vhd       # Batch normalization
â”‚   â”œâ”€â”€ axi/
â”‚   â”‚   â”œâ”€â”€ axi_lite_cnn_ctrl.vhd    # Control/status registers
â”‚   â”‚   â”œâ”€â”€ axis_video_input.vhd     # Video stream input
â”‚   â”‚   â””â”€â”€ axis_cnn_interconnect.vhd# Layer interconnect
â”‚   â””â”€â”€ video/
â”‚       â””â”€â”€ frame_buffer_ctrl.vhd    # Triple-buffered frame storage
â”œâ”€â”€ software/
â”‚   â”œâ”€â”€ include/
â”‚   â”‚   â””â”€â”€ cnn_accelerator.h        # Driver header
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ cnn_accelerator.c        # Driver implementation
â”‚       â””â”€â”€ main.c                   # Demo application
â”œâ”€â”€ testbench/
â”‚   â””â”€â”€ cnn_accelerator_tb.vhd       # VHDL testbench
â”œâ”€â”€ constraints/
â”‚   â””â”€â”€ zuboard_cnn.xdc              # Timing constraints
â”œâ”€â”€ models/
â”‚   â””â”€â”€ (pre-trained weights)        # Model weights in Q8.8 format
â”œâ”€â”€ xczu1cg-sbva484-1-e-cnn.tcl      # Main Vivado build script
â”œâ”€â”€ Makefile                         # Build automation
â””â”€â”€ README.md                        # This file
```

---

## ğŸ› ï¸ Requirements

### Hardware
- **Avnet ZUBoard 1CG** (xczu1cg-sbva484-1-e)
- USB JTAG programmer
- Optional: MIPI camera module

### Software
- **Xilinx Vivado 2024.2** (or compatible version)
- **Xilinx Vitis 2024.2**
- Linux/Windows with bash shell
- GNU Make

---

## ğŸš€ Quick Start

### 1. Clone and Setup

```bash
cd /path/to/workspace
git clone <repository-url>
cd zuboard_ai-edge-accelerator
```

### 2. Configure Environment

Source the Xilinx tools:

```bash
source source_me.vivado   # Vivado environment
source source_me.vitis    # Vitis environment
```

Or manually:

```bash
source /tools/Xilinx/Vivado/2024.2/settings64.sh
source /tools/Xilinx/Vitis/2024.2/settings64.sh
```

### 3. Build the Project

```bash
# Full build (Vivado + Vitis)
make build

# Or step by step:
make           # Build hardware only
make program   # Program the board
```

### 4. Simulation

```bash
make sim       # Run testbench simulation
```

---

## ğŸ“Š Register Map

The CNN accelerator is controlled via AXI-Lite registers at base address `0x80000000`:

| Offset | Name | Description |
|--------|------|-------------|
| 0x00 | CONTROL | Start/Stop/Reset control bits |
| 0x04 | STATUS | Busy/Done/Error status |
| 0x08 | CONFIG | Layer enable, activation, pooling |
| 0x0C | LAYER_CONFIG | Number of input/output channels |
| 0x10 | INPUT_ADDR | DMA address for input frame |
| 0x14 | OUTPUT_ADDR | DMA address for results |
| 0x18 | WEIGHT_ADDR | DMA address for weights |
| 0x1C | BIAS_ADDR | DMA address for biases |
| 0x20 | IRQ_ENABLE | Interrupt enable mask |
| 0x24 | IRQ_STATUS | Interrupt status (W1C) |
| 0x28 | RESULT_0/1 | Top classification results |
| 0x30 | PERF_CYCLES | Performance counter: cycles |
| 0x34 | PERF_OPS | Performance counter: MACs |

### Control Register (0x00)
- Bit 0: `START` - Begin inference
- Bit 1: `STOP` - Abort operation
- Bit 2: `RESET` - Soft reset

### Status Register (0x04)
- Bit 0: `BUSY` - Inference in progress
- Bit 1: `DONE` - Inference complete
- Bit 2: `ERROR` - Error occurred
- Bits 7:4: `STATE` - State machine state

---

## ğŸ’» Software API

### Basic Usage

```c
#include "cnn_accelerator.h"

int main() {
    CNN_Accelerator cnn;
    
    // Initialize with base address
    CNN_Init(&cnn, CNN_BASEADDR);
    
    // Load pre-trained weights
    CNN_LoadWeights(&cnn, weights_data, NUM_WEIGHTS);
    CNN_LoadBiases(&cnn, biases_data, NUM_BIASES);
    
    // Configure for inference
    CNN_SetInputAddress(&cnn, input_frame_addr);
    CNN_SetOutputAddress(&cnn, output_buffer_addr);
    
    // Start inference
    CNN_Start(&cnn);
    
    // Wait for completion
    while (!CNN_IsDone(&cnn)) {
        // Optionally do other work
    }
    
    // Get classification result
    uint32_t class_id = CNN_GetTopClass(&cnn);
    uint32_t confidence = CNN_GetConfidence(&cnn);
    
    printf("Detected class %d with confidence %d%%\n", 
           class_id, confidence);
    
    return 0;
}
```

### API Reference

| Function | Description |
|----------|-------------|
| `CNN_Init()` | Initialize accelerator driver |
| `CNN_Reset()` | Soft reset the accelerator |
| `CNN_LoadWeights()` | Load convolution weights |
| `CNN_LoadBiases()` | Load bias values |
| `CNN_SetInputAddress()` | Set DMA input buffer |
| `CNN_SetOutputAddress()` | Set DMA output buffer |
| `CNN_Start()` | Begin inference |
| `CNN_IsDone()` | Check completion status |
| `CNN_GetTopClass()` | Get top classification |
| `CNN_GetConfidence()` | Get confidence score |
| `CNN_GetCycleCount()` | Get performance cycles |

---

## âš™ï¸ Configuration

### Activation Functions

The accelerator supports multiple activation functions selectable via register:

| Value | Function | Formula |
|-------|----------|---------|
| 0 | None | `y = x` |
| 1 | ReLU | `y = max(0, x)` |
| 2 | Leaky ReLU | `y = x > 0 ? x : 0.1*x` |
| 3 | Sigmoid | `y = 1/(1+exp(-x))` [LUT] |

### Fixed-Point Format

All internal computations use **Q8.8 fixed-point**:
- 8 bits signed integer part
- 8 bits fractional part
- Range: -128.0 to +127.996
- Resolution: 0.00390625

Convert float to Q8.8: `int16_t q88 = (int16_t)(float_val * 256.0f);`

---

## ğŸ“ˆ Performance Estimates

### Resource Utilization

| Resource | Used | Available | % |
|----------|------|-----------|---|
| LUTs | ~15,000 | 37,440 | 40% |
| FFs | ~12,000 | 74,880 | 16% |
| BRAMs | ~30 | 216 | 14% |
| DSP48s | ~50 | 120 | 42% |

### Throughput

- **Clock Frequency**: 100 MHz
- **Inference Latency**: ~2ms (128x128x3 input)
- **Peak Throughput**: 500+ FPS (memory limited)
- **MAC Operations**: 3.2 GOPS

---

## ğŸ§ª Testing

### Run Testbench

```bash
# Batch simulation
make sim

# GUI simulation (waveforms)
make sim_gui
```

### Expected Output

```
========================================
  CNN Accelerator Testbench Starting   
========================================
Loading weights...
Weights loaded: 5040 values
Starting inference...
Inference complete: 15234 cycles
Top class: 3, Confidence: 92%
========================================
  TEST PASSED
========================================
```

---

## ğŸ› Troubleshooting

### Build Issues

**"Board part not found"**
- Install ZUBoard board files from Avnet website
- Place in `~/.Xilinx/Vivado/2024.2/board_files/`

**Timing violations**
- Reduce `C_AXI_CLK_FREQ_HZ` in TCL script
- Check synthesis report for critical paths

### Runtime Issues

**Inference hangs**
- Verify DMA addresses are 64-byte aligned
- Check `STATUS` register for error flags
- Ensure weights are loaded before starting

**Wrong classification**
- Verify weight format is Q8.8 signed
- Check input normalization (0-255 â†’ Q8.8)
- Validate model against software reference

---

## ğŸ—ºï¸ Roadmap

- [ ] Add depthwise separable convolution
- [ ] INT8 quantization support
- [ ] MIPI CSI-2 camera interface
- [ ] YOLO-style detection output
- [ ] ONNX model converter
- [ ] Batch processing mode

---

## ğŸ“š References

- [Zynq UltraScale+ MPSoC Technical Reference Manual (UG1085)](https://docs.xilinx.com/r/en-US/ug1085-zynq-ultrascale-trm)
- [Vivado Design Suite User Guide (UG910)](https://docs.xilinx.com/r/en-US/ug910-vivado-getting-started)
- [AXI Reference Guide (UG1037)](https://docs.xilinx.com/r/en-US/ug1037-vivado-axi-reference-guide)

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.
